---
title: "My_PMLCourseAnalysis"
output: html_document
---

# Practical ML Summer 2015

**Author**: Elizabeth Barayuga
This document provides an understanding of the course project of using Machine Learning (ML) algorithms to predict data. 

##Overview

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. 
<br>
These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 
<br>
In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 
<br>
More information is available from the website here: ***http://groupware.les.inf.puc-rio.br/har***
(see the section on the Weight Lifting Exercise Dataset).


##Data Involved in Model

THe following data were provided as part of the course exercise.

The training data for this project are available here: 
**https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv**

The test data are available here: 
**https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv**

The data for this project come from this source: **http://groupware.les.inf.puc-rio.br/har**. 


## Goal

The goal of your project is to predict the manner in which they did the exercise. 
<br>
This is the **"classe"** variable in the training set. 

There are a total of 160 possible predictors and can be used to predict the **"classe"** variable.

## Approach for Developing the Model

1. Analyze the values for each predictors
2. Cleanse the data 
3. Select possible features that would be used for the prediction model 
4. Identify possible method that would be used for prediction
5. Train the model selected by using training dataset. 
6. Identify a threshold for the training data that would be used for training 
7. Validate the model by running it to the testing set that was set-aside from the training data 
8. Check the confusion matrix for the performance of the model 
9. Once acceptable, run the final validation on the final testing file 

## Reproduceability 

The whole exercise was run in MAC OS X Yosemite (10.10.4) and RStudio Version 0.98.1091

Furthermore, certain libraries  were chosen to support the full exercise. To access these libraries, packages needs to be installed (if not yet installed) 
In order to install packages in R the following command can be used: 
        install.packages("caret")

If the packages are already installed, then the libraries can be invoked:
```{r}
library(caret)
library(ggplot2)
library(doMC)
library(knitr)
library(xtable)
library(randomForest)
library(doSNOW)
library(data.table)

```
We also chose a random seed to start the exercise. 

```{r}
### Set the seed so that the output is reproducible
set.seed(15)
```
## Accessing the Data 

In order to access the Data Sources, we have provided a way to download the data from the source sites and read the data into memory.

We also did an initial cleansing of data by removing the #DIV/0! values in read method 


```{r}
## Function: Download the input files provided in the Course
### pml-training.csv 
### pml-testing.csv 

download.data <- function() {
        download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv",method="curl")
        download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv",method="curl")
}

### Function: Read the file and clean it up 
### 1. Change all "#DIV/0! to blanks

read.data <- function(file){
        fread(file,na.strings=c("#DIV/0!",""))
}

### Create a rawtrain file to house the training data 
rawtrain <- read.data("/Users/user1/Documents/RWorkingDirectory/Coursera-May2015/pml-training.csv")

```
## Methodology for Cleansing Data 

        1. Replace all  #DIV/0! data as "NA" - accomplished during the read of the file into memory
        2. Represent all empty data as "NA"
        3. Identify which columns have "NA" as values and marked them accordingly.
	
```{r}
## Functions: Identify columns that contain NA and marked them accordingly
nacolumns <- rawtrain[,sapply(.SD, function(x) any(is.na(x)))]
```
## Feature Selection 

In any model, it would be good to analyze the data to see what features can be used to predict the **classe** variable. 

The general goal of a good model is to be able to use the right features that can generalize well that it can be used to model with unseen data. 

1. Run str to get an understanding of the different features available in training data. 
        
		str(training) 
	
2. Apply the cleansing strategies to the training data 
		
3. Identify columns that appear to provide metadata information and would contribute to over-fitting the model. Basing from the different attributes presented, the following columns can be eliminated:
		
		rownames - V1
		user_name 
		raw_timestamp_part_1
		raw_timestamp_part_2
		cvtd_timestamp
		new_window
		num_window


```{r}
### Function: Eliminate some columns that would not be used for predictions
### First 7 columns would not be used for the predictions that may skew the result 
dropcolumns <- function(x){
        x[,!c("V1","user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", 
              "cvtd_timestamp", "new_window", "num_window"),with=F]
}

### Function: Transform Features on the datasets
transformfeatures <- function(x){
        x[,classe:=factor(classe)]
}
```
## PARTITIONING TRAINING DATA FOR MODELING and CROSS VALIDATION 

After choosing our features and cleansing the data, we would be able to partition our training data set.


```{r}
### Determine features for training the model
rawtrainfeatures <- dropcolumns(rawtrain[,eval(names(which(nacolumns == F))),with=F])
### PARTITION Training data 
### Threshold being used is 60%

intrain  <- createDataPartition(rawtrainfeatures$classe, p=.60, list=FALSE)
training <- rawtrainfeatures[intrain[,1]]
testing  <- rawtrainfeatures[-intrain[,1]]
```
## Using ML algorithms for prediction : Random Forest

1.  Model is created using all variables in the training set 
2.  The value for randomly sampled variables is set to 3 (mtry=3)

```{r}
model.rf <- train(y=as.factor(training$classe), 
                  x=training[,!"classe",with=F], 
                  tuneGrid=data.frame(mtry=3), 
                  trControl=trainControl(method="none"), method="parRF") 
```
Predicting in-sample error using the testing partition from the training data set

```{r}
### Check for confusion matrix results 
confusionMatrix(predict(model.rf, newdata=transformfeatures(testing)), factor(testing$classe))
confusionMatrix(predict(model.rf, newdata=transformfeatures(testing)), factor(testing$classe))$overall["Kappa"]
```
The Plot for the Variable Impotence using in-sample error is:
```{r, echo=FALSE}
    print(plot(varImp(model.rf, scale = FALSE)))
```

## VALIDATION using the TESTING SET OUT-OF-SAMPLE ERROR
<br>
OUTPUT DIRECTORY: <Local R Working Directory> 
        i.e "/Users/user1/Documents/RWorkingDirectory/Coursera-May2015"
<br>
OUTPUT FILES: "problem_id_#[1:length(x)]
<br>
We create predictions for the entire testing set provided using the same cleansing and feature selection criteria that we used in the training set. 
There will be 1 file for each of the observations.


```{r}
##Function: Create the n files from running predictions using the testing file 
write.pml.predictions <- function(x){
        n = length(x)
        for(i in 1:n ) {
                filename = paste0("problem_id_",i,".txt")
                write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)      
        }        
}
### Run the model using the testing file we initial received 
### Read the ORIGINAL testing file that we have set-aside 

validateTesting <- read.data("~/Documents/RWorkingDirectory/Coursera-May2015/pml-testing.csv")


### Pass the testing file to see how the model.rf predicts the column classe
### using an unseen set of data 
### Using the function presented in the course, it would write out the predicted value for "classe"
### and write the files with the convention 
### problem_id_## where ## is 1 to length of the testing file 
### Using the original testing set-aside earlier do the following:
### 1. use the nacolumns to cleanse the find out the non-NA 
### 2. use the dropcolumns to drop not-needed columns for predictions

write.pml.predictions(predict(model.rf, 
        newdata=dropcolumns(validateTesting[,eval(names(which(nacolumns == F))[-60]),with=F])))
```

Here are some of the plots analyzed to see the relationship of the variables to the classe variable

```{r, echo=FALSE}
qplot(total_accel_belt,colour=classe,data=training,geom="density")
qplot(total_accel_arm,colour=classe,data=training,geom="density")
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

